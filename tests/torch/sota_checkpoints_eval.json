{
    "classification": {
        "imagenet": {
            "resnet50_imagenet": {
                "config": "examples/torch/classification/configs/quantization/resnet50_imagenet.json",
                "target": 76.16,
                "metric_type": "Acc@1",
                "model_description": "ResNet-50"
            },
            "resnet50_imagenet_int8": {
                "config": "examples/torch/classification/configs/quantization/resnet50_imagenet_int8.json",
                "reference": "resnet50_imagenet",
                "target": 76.42,
                "metric_type": "Acc@1",
                "resume": "resnet50_imagenet_int8.pth",
                "model_description": "ResNet-50",
                "compression_description": "INT8",
                "diff_fp32_min": -1,
                "diff_fp32_max": 0.5
            },
            "resnet50_imagenet_int8_per_tensor": {
                "config": "examples/torch/classification/configs/quantization/resnet50_imagenet_int8_per_tensor.json",
                "reference": "resnet50_imagenet",
                "target": 76.37,
                "metric_type": "Acc@1",
                "resume": "resnet50_imagenet_int8_per_tensor.pth",
                "model_description": "ResNet-50",
                "compression_description": "INT8 (per-tensor only)",
                "diff_fp32_min": -1,
                "diff_fp32_max": 0.5
            },
            "resnet50_imagenet_int4_int8": {
                "config": "examples/torch/classification/configs/mixed_precision/resnet50_imagenet_mixed_int_manual.json",
                "reference": "resnet50_imagenet",
                "target": 76.2,
                "metric_type": "Acc@1",
                "resume": "resnet50_imagenet_int4_int8.pth",
                "model_description": "ResNet-50",
                "compression_description": "Mixed, 44.8% INT8 / 55.2% INT4",
                "diff_fp32_min": -0.05,
                "diff_fp32_max": 0.4,
                "diff_target_min": -0.12,
                "diff_target_max": 0.12
            },
            "resnet50_imagenet_rb_sparsity_int8": {
                "config": "examples/torch/classification/configs/sparsity_quantization/resnet50_imagenet_rb_sparsity_int8.json",
                "reference": "resnet50_imagenet",
                "target": 75.43,
                "metric_type": "Acc@1",
                "resume": "resnet50_imagenet_rb_sparsity_int8.pth",
                "model_description": "ResNet-50",
                "compression_description": "INT8 + Sparsity 61% (RB)",
                "diff_fp32_min": -1,
                "diff_fp32_max": 0.15
            },
            "resnet50_imagenet_rb_sparsity50_int8": {
                "config": "examples/torch/classification/configs/sparsity_quantization/resnet50_imagenet_rb_sparsity50_int8.json",
                "reference": "resnet50_imagenet",
                "target": 75.55,
                "metric_type": "Acc@1",
                "resume": "resnet50_imagenet_rb_sparsity50_int8.pth",
                "model_description": "ResNet-50",
                "compression_description": "INT8 + Sparsity 50% (RB)",
                "diff_fp32_min": -1,
                "diff_fp32_max": 0.1
            },
            "mobilenet_v2_imagenet_int8": {
                "config": "examples/torch/classification/configs/quantization/mobilenet_v2_imagenet_int8.json",
                "reference": "mobilenet_v2_imagenet",
                "target": 71.35,
                "metric_type": "Acc@1",
                "resume": "mobilenet_v2_imagenet_int8.pth",
                "model_description": "MobileNet V2",
                "compression_description": "INT8",
                "diff_fp32_min": -1,
                "diff_fp32_max": 0.15
            },
            "mobilenet_v2_imagenet_int8_per_tensor": {
                "config": "examples/torch/classification/configs/quantization/mobilenet_v2_imagenet_int8_per_tensor.json",
                "reference": "mobilenet_v2_imagenet",
                "target": 71.3,
                "metric_type": "Acc@1",
                "resume": "mobilenet_v2_imagenet_int8_per_tensor.pth",
                "model_description": "MobileNet V2",
                "compression_description": "INT8 (per-tensor only)",
                "diff_fp32_min": -1,
                "diff_fp32_max": 0.15
            },
            "mobilenet_v2_imagenet_int4_int8": {
                "config": "examples/torch/classification/configs/mixed_precision/mobilenet_v2_imagenet_mixed_int_manual.json",
                "reference": "mobilenet_v2_imagenet",
                "target": 70.92,
                "metric_type": "Acc@1",
                "resume": "mobilenet_v2_imagenet_int4_int8.pth",
                "model_description": "MobileNet V2",
                "compression_description": "Mixed, 46.6% INT8 / 53.4% INT4",
                "diff_fp32_min": -1.05,
                "diff_fp32_max": 0.1
            },
            "mobilenet_v2_imagenet_rb_sparsity_int8": {
                "config": "examples/torch/classification/configs/sparsity_quantization/mobilenet_v2_imagenet_rb_sparsity_int8.json",
                "reference": "mobilenet_v2_imagenet",
                "target": 71.11,
                "metric_type": "Acc@1",
                "resume": "mobilenet_v2_imagenet_rb_sparsity_int8.pth",
                "model_description": "MobileNet V2",
                "compression_description": "INT8 + Sparsity 52% (RB)",
                "diff_fp32_min": -1,
                "diff_fp32_max": 0.15
            },
            "icnet_camvid_int8": {
                "config": "examples/torch/semantic_segmentation/configs/icnet_camvid_int8.json",
                "reference": "icnet_camvid",
                "target": 67.86,
                "metric_type": "Mean IoU",
                "resume": "icnet_camvid_int8.pth",
                "mean_value": "[99.603,103.329,105.6567]",
                "scale_value": "[75.643,77.821,76.746]",
                "model_description": "ICNet",
                "compression_description": "INT8",
                "diff_fp32_min": -1,
                "diff_fp32_max": 0.1
                
            },
            "icnet_camvid_magnitude_sparsity_int8": {
                "config": "examples/torch/semantic_segmentation/configs/icnet_camvid_magnitude_sparsity_int8.json",
                "reference": "icnet_camvid",
                "target": 67.18,
                "metric_type": "Mean IoU",
                "resume": "icnet_camvid_magnitude_sparsity_int8.pth",
                "mean_value": "[99.603,103.329,105.6567]",
                "scale_value": "[75.643,77.821,76.746]",
                "model_description": "ICNet",
                "compression_description": "INT8 + Sparsity 60% (Magnitude)",
                "diff_fp32_min": -1,
                "diff_fp32_max": 0.1
            }
        }
    }
}
